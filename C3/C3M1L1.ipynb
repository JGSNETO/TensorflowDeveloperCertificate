{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7858d9d4-b280-4fee-8762-7a82cf08bd46",
   "metadata": {},
   "source": [
    "# Natural Language processing in Tensorflow\n",
    "\n",
    "- Unlike images, which come in these mere regular shaped tensors of pixel intensity values, text is messier.\n",
    "- Learn how to load into text, preprocess it, and set up your data so it can be fed to a neural network.  \n",
    "\n",
    "# Word Based Encondings\n",
    "-  You learned about neural networks and how they can match patterns to perform classifications, and then how you can give them new data and have them predict what they might be seeing.\n",
    "- You learned how to make that a little smarter for images, using convolutions to identify the features in the images and classify based on those, instead of just matching on raw pixels. \n",
    "- We could take character encodings for each character in a set, for example, their ASCII values.\n",
    "- But the problem with this, of course, is that the semantics of the word aren't encoded in the letters.\n",
    "- So it seems that training a neural network with just the letters could be a daunting task.\n",
    "- What if we could give words a value and have those values used in training a network?\n",
    "- What that value is doesnt matter, its just that we have a value per word, and the value is the same for the same word every time. So a simple encoding for this sentence would be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc2264",
   "metadata": {},
   "source": [
    "# Using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04a777-cdfe-42f7-bca6-597e7682ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat'\n",
    "]\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization()\n",
    "vectorize_layer.adapt(sentences)\n",
    "vocabulary = vectorize_layer.get_vocabulary(include_special_tikens = False)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'you love my dog!'\n",
    "]\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization()\n",
    "vectorize_layer.adapt(sentences)\n",
    "vocabulary = vectorize_layer.get_vocabulary()\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd9169",
   "metadata": {},
   "source": [
    "# Text to Sequence\n",
    "\n",
    "- We saw how to tokenize the words and sentences.\n",
    "- The next step will be to turn your sentences into lists of values based on these tokens.\n",
    "-  Once you have them, you'll likely also need to manipulate these lists, not least to make every sentence the same length. Otherwise, it may be hard to train a neural network with them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

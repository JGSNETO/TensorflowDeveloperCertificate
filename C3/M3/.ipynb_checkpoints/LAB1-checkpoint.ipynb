{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6607ca66-ad31-44c0-b3ec-acf9bb2d17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802b19a6-fdb8-488a-be2a-1848cfab1b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72a23e2-3415-465c-abf7-5340605e7e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract_reasoning\n",
      "accentdb\n",
      "aeslc\n",
      "aflw2k3d\n",
      "ag_news_subset\n",
      "ai2_arc\n",
      "ai2_arc_with_ir\n",
      "amazon_us_reviews\n",
      "anli\n",
      "answer_equivalence\n",
      "arc\n",
      "asqa\n",
      "asset\n",
      "assin2\n",
      "bair_robot_pushing_small\n",
      "bccd\n",
      "beans\n",
      "bee_dataset\n",
      "beir\n",
      "big_patent\n",
      "bigearthnet\n",
      "billsum\n",
      "binarized_mnist\n",
      "binary_alpha_digits\n",
      "ble_wind_field\n",
      "blimp\n",
      "booksum\n",
      "bool_q\n",
      "bucc\n",
      "c4\n",
      "c4_wsrs\n",
      "caltech101\n",
      "caltech_birds2010\n",
      "caltech_birds2011\n",
      "cardiotox\n",
      "cars196\n",
      "cassava\n",
      "cats_vs_dogs\n",
      "celeb_a\n",
      "celeb_a_hq\n",
      "cfq\n",
      "cherry_blossoms\n",
      "chexpert\n",
      "cifar10\n",
      "cifar100\n",
      "cifar100_n\n",
      "cifar10_1\n",
      "cifar10_corrupted\n",
      "cifar10_n\n",
      "citrus_leaves\n",
      "cityscapes\n",
      "civil_comments\n",
      "clevr\n",
      "clic\n",
      "clinc_oos\n",
      "cmaterdb\n",
      "cnn_dailymail\n",
      "coco\n",
      "coco_captions\n",
      "coil100\n",
      "colorectal_histology\n",
      "colorectal_histology_large\n",
      "common_voice\n",
      "conll2002\n",
      "conll2003\n",
      "controlled_noisy_web_labels\n",
      "coqa\n",
      "cos_e\n",
      "cosmos_qa\n",
      "covid19\n",
      "covid19sum\n",
      "crema_d\n",
      "criteo\n",
      "cs_restaurants\n",
      "curated_breast_imaging_ddsm\n",
      "cycle_gan\n",
      "d4rl_adroit_door\n",
      "d4rl_adroit_hammer\n",
      "d4rl_adroit_pen\n",
      "d4rl_adroit_relocate\n",
      "d4rl_antmaze\n",
      "d4rl_mujoco_ant\n",
      "d4rl_mujoco_halfcheetah\n",
      "d4rl_mujoco_hopper\n",
      "d4rl_mujoco_walker2d\n",
      "dart\n",
      "davis\n",
      "deep1b\n",
      "deep_weeds\n",
      "definite_pronoun_resolution\n",
      "dementiabank\n",
      "diabetic_retinopathy_detection\n",
      "diamonds\n",
      "div2k\n",
      "dmlab\n",
      "doc_nli\n",
      "dolphin_number_word\n",
      "domainnet\n",
      "downsampled_imagenet\n",
      "drop\n",
      "dsprites\n",
      "dtd\n",
      "duke_ultrasound\n",
      "e2e_cleaned\n",
      "efron_morris75\n",
      "emnist\n",
      "eraser_multi_rc\n",
      "esnli\n",
      "eurosat\n",
      "fashion_mnist\n",
      "flic\n",
      "flores\n",
      "food101\n",
      "forest_fires\n",
      "fuss\n",
      "gap\n",
      "geirhos_conflict_stimuli\n",
      "gem\n",
      "genomics_ood\n",
      "german_credit_numeric\n",
      "gigaword\n",
      "glove100_angular\n",
      "glue\n",
      "goemotions\n",
      "gov_report\n",
      "gpt3\n",
      "gref\n",
      "groove\n",
      "grounded_scan\n",
      "gsm8k\n",
      "gtzan\n",
      "gtzan_music_speech\n",
      "hellaswag\n",
      "higgs\n",
      "hillstrom\n",
      "horses_or_humans\n",
      "howell\n",
      "i_naturalist2017\n",
      "i_naturalist2018\n",
      "i_naturalist2021\n",
      "imagenet2012\n",
      "imagenet2012_corrupted\n",
      "imagenet2012_fewshot\n",
      "imagenet2012_multilabel\n",
      "imagenet2012_real\n",
      "imagenet2012_subset\n",
      "imagenet_a\n",
      "imagenet_lt\n",
      "imagenet_pi\n",
      "imagenet_r\n",
      "imagenet_resized\n",
      "imagenet_sketch\n",
      "imagenet_v2\n",
      "imagenette\n",
      "imagewang\n",
      "imdb_reviews\n",
      "irc_disentanglement\n",
      "iris\n",
      "istella\n",
      "kddcup99\n",
      "kitti\n",
      "kmnist\n",
      "laion400m\n",
      "lambada\n",
      "lfw\n",
      "librispeech\n",
      "librispeech_lm\n",
      "libritts\n",
      "ljspeech\n",
      "lm1b\n",
      "locomotion\n",
      "lost_and_found\n",
      "lsun\n",
      "lvis\n",
      "malaria\n",
      "math_dataset\n",
      "math_qa\n",
      "mctaco\n",
      "media_sum\n",
      "mlqa\n",
      "mnist\n",
      "mnist_corrupted\n",
      "movie_lens\n",
      "movie_rationales\n",
      "movielens\n",
      "moving_mnist\n",
      "mrqa\n",
      "mslr_web\n",
      "mt_opt\n",
      "mtnt\n",
      "multi_news\n",
      "multi_nli\n",
      "multi_nli_mismatch\n",
      "natural_instructions\n",
      "natural_questions\n",
      "natural_questions_open\n",
      "newsroom\n",
      "nsynth\n",
      "nyu_depth_v2\n",
      "ogbg_molpcba\n",
      "omniglot\n",
      "open_images_challenge2019_detection\n",
      "open_images_v4\n",
      "openbookqa\n",
      "opinion_abstracts\n",
      "opinosis\n",
      "opus\n",
      "oxford_flowers102\n",
      "oxford_iiit_pet\n",
      "para_crawl\n",
      "pass\n",
      "patch_camelyon\n",
      "paws_wiki\n",
      "paws_x_wiki\n",
      "penguins\n",
      "pet_finder\n",
      "pg19\n",
      "piqa\n",
      "places365_small\n",
      "placesfull\n",
      "plant_leaves\n",
      "plant_village\n",
      "plantae_k\n",
      "protein_net\n",
      "q_re_cc\n",
      "qa4mre\n",
      "qasc\n",
      "quac\n",
      "quality\n",
      "quickdraw_bitmap\n",
      "race\n",
      "radon\n",
      "reddit\n",
      "reddit_disentanglement\n",
      "reddit_tifu\n",
      "ref_coco\n",
      "resisc45\n",
      "rlu_atari\n",
      "rlu_atari_checkpoints\n",
      "rlu_atari_checkpoints_ordered\n",
      "rlu_control_suite\n",
      "rlu_dmlab_explore_object_rewards_few\n",
      "rlu_dmlab_explore_object_rewards_many\n",
      "rlu_dmlab_rooms_select_nonmatching_object\n",
      "rlu_dmlab_rooms_watermaze\n",
      "rlu_dmlab_seekavoid_arena01\n",
      "rlu_locomotion\n",
      "rlu_rwrl\n",
      "robomimic_mg\n",
      "robomimic_mh\n",
      "robomimic_ph\n",
      "robonet\n",
      "robosuite_panda_pick_place_can\n",
      "rock_paper_scissors\n",
      "rock_you\n",
      "s3o4d\n",
      "salient_span_wikipedia\n",
      "samsum\n",
      "savee\n",
      "scan\n",
      "scene_parse150\n",
      "schema_guided_dialogue\n",
      "sci_tail\n",
      "scicite\n",
      "scientific_papers\n",
      "scrolls\n",
      "sentiment140\n",
      "shapes3d\n",
      "sift1m\n",
      "simpte\n",
      "siscore\n",
      "smallnorb\n",
      "smartwatch_gestures\n",
      "snli\n",
      "so2sat\n",
      "speech_commands\n",
      "spoken_digit\n",
      "squad\n",
      "squad_question_generation\n",
      "stanford_dogs\n",
      "stanford_online_products\n",
      "star_cfq\n",
      "starcraft_video\n",
      "stl10\n",
      "story_cloze\n",
      "summscreen\n",
      "sun397\n",
      "super_glue\n",
      "svhn_cropped\n",
      "symmetric_solids\n",
      "tao\n",
      "tatoeba\n",
      "ted_hrlr_translate\n",
      "ted_multi_translate\n",
      "tedlium\n",
      "tf_flowers\n",
      "the300w_lp\n",
      "tiny_shakespeare\n",
      "titanic\n",
      "trec\n",
      "trivia_qa\n",
      "tydi_qa\n",
      "uc_merced\n",
      "ucf101\n",
      "unified_qa\n",
      "universal_dependencies\n",
      "unnatural_instructions\n",
      "user_libri_audio\n",
      "user_libri_text\n",
      "vctk\n",
      "visual_domain_decathlon\n",
      "voc\n",
      "voxceleb\n",
      "voxforge\n",
      "waymo_open_dataset\n",
      "web_graph\n",
      "web_nlg\n",
      "web_questions\n",
      "webvid\n",
      "wider_face\n",
      "wiki40b\n",
      "wiki_auto\n",
      "wiki_bio\n",
      "wiki_dialog\n",
      "wiki_table_questions\n",
      "wiki_table_text\n",
      "wikiann\n",
      "wikihow\n",
      "wikipedia\n",
      "wikipedia_toxicity_subtypes\n",
      "wine_quality\n",
      "winogrande\n",
      "wit\n",
      "wit_kaggle\n",
      "wmt13_translate\n",
      "wmt14_translate\n",
      "wmt15_translate\n",
      "wmt16_translate\n",
      "wmt17_translate\n",
      "wmt18_translate\n",
      "wmt19_translate\n",
      "wmt_t2t_translate\n",
      "wmt_translate\n",
      "wordnet\n",
      "wsc273\n",
      "xnli\n",
      "xquad\n",
      "xsum\n",
      "xtreme_pawsx\n",
      "xtreme_pos\n",
      "xtreme_s\n",
      "xtreme_xnli\n",
      "yahoo_ltrc\n",
      "yelp_polarity_reviews\n",
      "yes_no\n",
      "youtube_vis\n"
     ]
    }
   ],
   "source": [
    "datasets = tfds.list_builders()\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea0aeb5f-ede9-4efe-8ff0-deed42eee9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ../data/imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72211dd4a1874b73a9c6f8b9ba336fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a42017710f74dda8fb5b6cece2756dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ..\\data\\imdb_reviews\\plain_text\\1.0.0.incomplete5OZLUT\\imdb_reviews-train.tfrecord*...:   0%|       …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ..\\data\\imdb_reviews\\plain_text\\1.0.0.incomplete5OZLUT\\imdb_reviews-test.tfrecord*...:   0%|        …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ..\\data\\imdb_reviews\\plain_text\\1.0.0.incomplete5OZLUT\\imdb_reviews-unsupervised.tfrecord*...:   0%|…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to ../data/imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The dataset is already downloaded for you. For downloading you can use the code below.\n",
    "imdb = tfds.load(\"imdb_reviews\", as_supervised=True, data_dir=\"../data/\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a109955-8cb8-4244-b8ff-72981c06941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the train reviews and labels\n",
    "train_reviews = imdb['train'].map(lambda review, label: review)\n",
    "train_labels = imdb['train'].map(lambda review, label: label)\n",
    "\n",
    "# Extract the test reviews and labels\n",
    "test_reviews = imdb['test'].map(lambda review, label: review)\n",
    "test_labels = imdb['test'].map(lambda review, label: label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c076d-df11-4d5e-9d5d-5d25f2005076",
   "metadata": {},
   "source": [
    "# Download the subword vocabulary (not needed in Coursera)\n",
    "# !wget -nc https://storage.googleapis.com/tensorflow-1-public/course3/imdb_vocab_subwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bedf06-7ff3-4000-a1f9-34a1886995a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the subword tokenizer\n",
    "subword_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary='./imdb_vocab_subwords.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c50c09-dddc-4186-b838-b5f29827fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline and padding parameters\n",
    "SHUFFLE_BUFFER_SIZE = 10000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 256\n",
    "PADDING_TYPE = 'pre'\n",
    "TRUNC_TYPE = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27867e49-6f68-4c37-a7ae-bb29519906aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_func(sequences):\n",
    "  '''Generates padded sequences from a tf.data.Dataset'''\n",
    "\n",
    "  # Put all elements in a single ragged batch\n",
    "  sequences = sequences.ragged_batch(batch_size=sequences.cardinality())\n",
    "\n",
    "  # Output a tensor from the single batch\n",
    "  sequences = sequences.get_single_element()\n",
    "\n",
    "  # Pad the sequences\n",
    "  padded_sequences = tf.keras.utils.pad_sequences(sequences.numpy(), truncating=TRUNC_TYPE, padding=PADDING_TYPE)\n",
    "\n",
    "  # Convert back to a tf.data.Dataset\n",
    "  padded_sequences = tf.data.Dataset.from_tensor_slices(padded_sequences)\n",
    "\n",
    "  return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba382888-e0a6-4593-8900-3acc51965114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate integer sequences using the subword tokenizer\n",
    "train_sequences_subword = train_reviews.map(lambda review: subword_tokenizer.tokenize(review)).apply(padding_func)\n",
    "test_sequences_subword = test_reviews.map(lambda review: subword_tokenizer.tokenize(review)).apply(padding_func)\n",
    "\n",
    "# Combine the integer sequence and labels\n",
    "train_dataset_vectorized = tf.data.Dataset.zip(train_sequences_subword,train_labels)\n",
    "test_dataset_vectorized = tf.data.Dataset.zip(test_sequences_subword,test_labels)\n",
    "\n",
    "# Optimize the datasets for training\n",
    "train_dataset_final = (train_dataset_vectorized\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .cache()\n",
    "                       .prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
    "                       .batch(BATCH_SIZE)\n",
    "                       )\n",
    "\n",
    "test_dataset_final = (test_dataset_vectorized\n",
    "                      .cache()\n",
    "                      .prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
    "                      .batch(BATCH_SIZE)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ebc95-fd3a-435e-97d1-3ba6486725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "EMBEDDING_DIM = 64\n",
    "LSTM_DIM = 64\n",
    "DENSE_DIM = 64\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(None,)),\n",
    "    tf.keras.layers.Embedding(subword_tokenizer.vocabulary_size(), EMBEDDING_DIM),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_DIM)),\n",
    "    tf.keras.layers.Dense(DENSE_DIM, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f5999-95ea-4eb9-be95-7a99222dabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6300d7-799e-4423-a468-769ac68e0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_dataset_final, epochs=NUM_EPOCHS, validation_data=test_dataset_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f298179-e274-4717-96b2-3b2ebbb07e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "  '''Plots the training and validation loss and accuracy from a history object'''\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "  ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "  ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  ax[0].set_title('Training and validation accuracy')\n",
    "  ax[0].set_xlabel('epochs')\n",
    "  ax[0].set_ylabel('accuracy')\n",
    "  ax[0].legend()\n",
    "\n",
    "  ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
    "  ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "  ax[1].set_title('Training and validation loss')\n",
    "  ax[1].set_xlabel('epochs')\n",
    "  ax[1].set_ylabel('loss')\n",
    "  ax[1].legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a299f7-ce6a-465f-a99d-ddaae6cd82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the kernel to free up resources. \n",
    "# Note: You can expect a pop-up when you run this cell. You can safely ignore that and just press `Ok`.\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "k = get_ipython().kernel\n",
    "\n",
    "k.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
